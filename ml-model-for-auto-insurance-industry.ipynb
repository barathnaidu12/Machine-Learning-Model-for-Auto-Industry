{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ML Model for Auto Insurance Industry"},{"metadata":{},"cell_type":"markdown","source":"### Aim of the Project\n> The aim of the project is to build a Machine Learning Model to predict whether an owner will initiate an auto insurance claim in the next year.\n\n### Background\n> The auto insurance industry is witnessing a paradigm shift. Since auto insurance company consists of homogenous good thereby making it difficult to differentiate product A from product B, also companies are fighting a price war (for insurance price). On top of that, the distribution channel is shifting more from traditional insurance brokers to online purchases, which means that the ability for companies to interact through human touchpoints is limited, and customers should be quoted at a reasonable price. A good price quote is one that makes the customer purchase the policy and helps the company to increase the profits.\nAlso, the insurance premium is calculated based on more than 50+ parameters, which means that traditional business analytics-based algorithms are now limited in their ability to differentiate among customers based on subtle parameters.\n\n**The model shall mainly support the following use cases:**\n\n>**1. Conquering Market Share:** Capture market share by lowering the prices of the premium for the customers, who are least likely to claim.\n\n>**2. Risk Management:** Charge the right premium from the customer, who is likely to claim insurance in the coming year\n\n>**3. Smooth Processing:** Reduce the complexity of pricing models. Most of the transactions are happening online with larger customer attributes (thanks to the internet and social media). Harness the power of huge data to build complex ML models\n\n>**4. Increased Profits:** As per industry estimate 1% reduction in the claim can boost profit by 10%. So, through the ML model, we can identify and deny the insurance to the driver who will make a claim. Thus, ensuring reduced claim outgo and increased profit.\n\nPart of the model development is to identify and prioritize the above use cases."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom datetime import datetime\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix,mean_squared_error,accuracy_score\nfrom sklearn.metrics import precision_score,recall_score,roc_auc_score,f1_score,cohen_kappa_score\nfrom sklearn.utils import resample\nfrom pprint import pprint\n\nimport plotly as py\nimport plotly.graph_objs as go\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\nfrom IPython.display import Markdown, display\nimport statsmodels.api as sm # import API\nfrom matplotlib.pyplot import xticks\n\nsns.set(style=\"whitegrid\")\npd.set_option('display.max_columns', 100)\npy.offline.init_notebook_mode(connected=True)\npd.options.display.float_format = '{:20,.2f}'.format \nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Data Helper Utilities\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def log(string):\n    display(Markdown(\"> <span style='color:blue'>\"+string+\"</span>\"))\n\ndef header(string):\n    display(Markdown(\"------ \"))\n    display(Markdown(\"### \"+string))\n\ndef get_variable_type(element) :\n    \"\"\"\n     Check is columns are of Continuous or Categorical variable.\n     Assumption is that if \n                 unique count < 20 then categorical \n                 unique count >= 20 and dtype = [int64 or float64] then continuous\n     \"\"\"\n    if element==0:\n        return \"Not Known\"\n    elif element < 20 and element!=0 :\n        return \"Categorical\"\n    elif element >= 20 and element!=0 :\n        return \"Contineous\"\n\ndef predict_variable_type(metadata_matrix):\n    metadata_matrix[\"Variable_Type\"] = metadata_matrix[\"Unique_Values_Count\"].apply(get_variable_type).astype(str)\n    metadata_matrix[\"frequency\"] = metadata_matrix[\"Null_Count\"] - metadata_matrix[\"Null_Count\"]\n    metadata_matrix[\"frequency\"].astype(int)\n    return metadata_matrix \n\ndef get_meta_data(dataframe) :\n    \"\"\"\n     Method to get Meta-Data about any dataframe passed \n    \"\"\"\n    metadata_matrix = pd.DataFrame({\n                    'Datatype' : dataframe.dtypes.astype(str), # data types of columns\n                    'Non_Null_Count': dataframe.count(axis = 0).astype(int), # total elements in columns\n                    'Null_Count': dataframe.isnull().sum().astype(int), # total null values in columns\n                    'Null_Percentage': dataframe.isnull().sum()/len(dataframe) * 100, # percentage of null values\n                    'Unique_Values_Count': dataframe.nunique().astype(int) # number of unique values\n                     })\n    \n    metadata_matrix = predict_variable_type(metadata_matrix)\n    return metadata_matrix\n\ndef plot_data_pie_chat(dataframe,col) : \n    header(\"Stats for \"+col+\" Datatype Percentage Distribution\")\n    dataframe_group = dataframe.groupby(col).frequency.count().reset_index()\n    dataframe_group.sort_values([col], axis=0,ascending=False, inplace=True)\n    trace = go.Pie(labels=dataframe_group[col].tolist(), values=dataframe_group[\"frequency\"].tolist())\n    layout = go.Layout(title=\"Datatype Percentage Distribution\")\n    fig = go.Figure(data=[trace], layout=layout)    \n    py.offline.iplot(fig)\n\ndef pairplot(x_axis,y_axis) :\n    sns.pairplot(car_df,x_vars=x_axis,y_vars=y_axis,height=4,aspect=1,kind=\"scatter\")\n    plt.show()\n\ndef heatmap(x,y,dataframe):\n    plt.figure(figsize=(x,y))\n    sns.heatmap(dataframe.corr(),cmap=\"OrRd\",annot=True)\n    plt.show()\n\ndef bar_count_plot(dataframe,col_name) :\n    plt.figure(figsize=(16,8))\n    plt.title(col_name + 'Histogram')\n    sns.countplot(dataframe[col_name], palette=(\"plasma\"))\n    xticks(rotation = 90)\n    plt.show()\n\ndef color_red(val):\n    \"\"\"\n    Takes a scalar and returns a string with\n    the css property `'color: red'` for value \n    greater than 10 , black otherwise.\n    \"\"\"\n    color = 'red' if val > 5 else 'black'\n    return 'color: %s' % color\n\ndef accuracy_result(y_test, y_pred_test):\n    from sklearn import metrics\n    from sklearn.metrics import confusion_matrix, classification_report\n    confusion_matrix=metrics.confusion_matrix(y_test, y_pred_test)\n    # USE THE IMPORTED CONFUSION MATRIX\n    print('\\n CONFUSION MATRIX:\\n ', confusion_matrix,'\\n')\n    TP = confusion_matrix[1, 1]\n    TN = confusion_matrix[0, 0]\n    FP = confusion_matrix[0, 1]\n    FN = confusion_matrix[1, 0]\n    false_positive_rate = round(FP / float(TN + FP),3)\n    print('FPR: ', false_positive_rate)\n    print('TPR/ RECALL/ SENSTIVITY: ', round(metrics.recall_score(y_test, y_pred_test), 3))\n    print('PRECISION:' ,round(metrics.precision_score(y_test, y_pred_test), 3))\n    specificity = round(TN / (TN + FP),3)\n    print('SPECIFICITY: ',specificity)\n    print('ACCURACY: ', np.round(metrics.accuracy_score(y_test, y_pred_test),3))\n    print('ROC AUC: ', np.round(roc_auc_score(y_test, y_pred_test),3))\n    print('Cohens kappa: ',np.round(cohen_kappa_score(y_test, y_pred_test),3))\n    print('F1 score: ', np.round(f1_score(y_test, y_pred_test),3))\n    print('\\n CLASSIFICATION REPORT: \\n',classification_report(y_test,y_pred_test))\n    return ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Import data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/train(1).csv')\ndf1= df.copy()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df[:200000]\n_X = temp.drop(['id','target'],axis =1)\n_y=temp.target\nmetadata_matrix_dataframe = get_meta_data(df)\nmetadata_matrix_dataframe[\"dt_name\"] =[ i.split(\"_\")[-1] for i in metadata_matrix_dataframe.index.values]\nmetadata_matrix_dataframe['dt_name'] = metadata_matrix_dataframe['dt_name'].apply(lambda x : \"interval\" if str(x).isnumeric() else x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Dtype = metadata_matrix_dataframe.groupby(['dt_name'])\n\ninterval_feature =Dtype.get_group(\"interval\").index.tolist()\nbin_feature = Dtype.get_group(\"bin\").index.tolist()\ncat_feature = Dtype.get_group(\"cat\").index.tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1. Write at least 3 important inferences from the data above**\n\n**Ans.:**\n\n1. Data is higly imblaced, target distribtion is:\n    >0 = 96.36 %\n    \n    >1 = 3.64 %\n    \n2. data have vaiable type:\n    > Interval = 45.6\n    \n    > binary =29.8\n    \n    > categorical = 24.6\n\n3. Most of the features are uncorrelated\n    "},{"metadata":{},"cell_type":"markdown","source":"**2. Is the data balanced? Meaning are targets 0 and 1 in the right proportion?**\n\n**Ans.:** No, data not balanced. I shown below."},{"metadata":{"trusted":true},"cell_type":"code","source":"perc = (df['target'].value_counts()/(df.shape[0]))*100\nprint(\"Percentge distribution of class '1' & class '0':\\n\\n\",perc)\nperc.plot.bar();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**3. How many categorical features are there?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"group_variable_type = metadata_matrix_dataframe.groupby('Variable_Type')\nprint(\"categorical features count:\",group_variable_type.get_group('Categorical').shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**5. Write inferences from data on interval variables**"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df[interval_feature].corr()\ntemp = temp[(temp>=0.5) | (temp<=-0.5)].fillna(0)\nfig, ax = plt.subplots(figsize=(12,10))\nsns.heatmap(temp,linewidths=.5, cmap=\"YlGnBu\",ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log(\"Analysis : Almost all the features are independent, Looking at above plot only 3 features are correlated with correlation near 0.5.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**6. Write inferences from data on ordinal variables.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"d ={}\nfor i in df[cat_feature].columns:\n    d[i] = df[cat_feature][i].nunique()\n\npd.DataFrame(d,index=['unique values']).T.plot.bar(figsize=(16,8));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log(\"Analysis : Looking at above graph only one feature have unqiue values more than 20\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**7. Write inferences from data on binary variables.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"col = metadata_matrix_dataframe[metadata_matrix_dataframe['Unique_Values_Count'] == 2].index\ndf_1 = pd.DataFrame((df[col].sum()/df[col].shape[0])*100, columns=['Percentage of 1'])\ndf_1.plot.bar(figsize=(16,8));\nlog(\"Analysis : Looking at above graph % of 1's is near near for *ps_ind_10_bin, ps_ind_11_bin, ps_ind_12_bin, ps_ind_13_bin.\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 11. Which are the top two features in terms of missing values?\n\n> No Missing Value Found.\n\n#### 12. In total, how many features have missing values?\n\n> No Feature having missing values\n\n#### 13. What steps should be taken to handle the missing data?\n\n> **NA**"},{"metadata":{},"cell_type":"markdown","source":"#### 8. Check if the target data is proportionate or not. Hint: Below than 30% for binary data is sign of imbalance"},{"metadata":{"trusted":true},"cell_type":"code","source":"Per1= np.round((df[df['target']==1].shape[0]*100)/ df.shape[0],2)\nPer0= np.round((df[df['target']==0].shape[0]*100)/ df.shape[0],2)\n\nprint('Target=1 shape:',df[df['target']==1].shape, Per1,'%','\\nTarget=0 shape:',df[df['target']==0].shape,Per0,'%')\nprint(\"\\n # This Data shows that it's imbalanced\")\nsns.countplot(x= df['target'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**9. What should be the preferred way in this case to balance the data?**\n\n> The most popular solution to an imbalanced classification problem is to change the composition of the training dataset.Techniques designed to change the class distribution in the training dataset are generally referred to as sampling methods or resampling methods as we are sampling an existing data sample.\n\n"},{"metadata":{},"cell_type":"markdown","source":"**10. How many training records are there after achieving a balance of 12%?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# using resampling technique, splittinf data into classes\ndf_mino= df[df['target']==1]\ndf_majo= df[df['target']==0]\ndf_mino_upsampled = resample(df_mino,replace=True,n_samples=int(len(df_majo)*0.12), random_state = 42)\n\nprint(\"Size of data, after achieving a balance of 12%: \", df_mino_upsampled.shape[0] + df_majo.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Applying Resampling to make balance data-set"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mino_upsampled = resample(df_mino,replace=True,n_samples=len(df_majo), random_state = 42)\ndf = pd.concat([df_majo,df_mino_upsampled])\nprint(\"Class compostion after resampling:\")\nprint(df['target'].value_counts())\ndf['target'].value_counts().plot.bar();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">Now here we have both class with equall count"},{"metadata":{},"cell_type":"markdown","source":"#### 14. Which interval variables have strong correlation?"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df[interval_feature].corr()\ntemp = temp[(temp>=0.5) | (temp<=-0.5)].fillna(0)\nfig, ax = plt.subplots(figsize=(12,10))\nsns.heatmap(temp,linewidths=.5, cmap=\"YlGnBu\",ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> interval Variable with high correlation(abs value more than 0.5)\n1. ps_reg_03 --> ps_reg_03 & ps_reg_03\n2. ps_reg_13 --> ps_reg_12"},{"metadata":{},"cell_type":"markdown","source":"#### 15. What's the level of correlation among ordinal features?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# cutoff = 0.3\ntemp = df[cat_feature].corr()\ntemp = temp[(temp>=0.3) | (temp<=-0.3)].fillna(0)\nfig, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(temp,linewidths=.3, cmap=\"YlGnBu\",ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ordinal Variable with high correlation(abs value more than 0.5)\n1. ps_car_03_cat --> ps_car_05_cat\n2. ps_car_05_cat --> ps_car_09_cat"},{"metadata":{},"cell_type":"markdown","source":"#### 16. Implement Hot Encoding for categorical features\n\n**NA**\n> No, nominal Features are available\n\n#### 17. In nominal and interval features, which features are suitable for StandardScaler?\n\n>Nominal featues are not suitable for StandardScaler\n\n>We can apply StandardScaler in interval features"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf=RandomForestClassifier(n_estimators=100)\nclf.fit(_X,_y)\n\nfeature_imp = pd.Series(clf.feature_importances_,index=_X.columns).sort_values(ascending=False)\nimp = pd.DataFrame(feature_imp).reset_index()\nimp.columns = [\"Features\", 'Imp']\n\nimp['Imp'] = (imp['Imp']/max(imp['Imp']))*100\ncol = imp[imp[\"Imp\"]>25]['Features'].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a bar plot\nplt.figure(figsize = (20,7))\nsns.barplot(x=_X.columns, y=imp.Imp)\nplt.xlabel('Feature Importance Score')\nplt.ylabel('Features')\nplt.title(\"Visualizing Important Features\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Top 10 ordered important features\")\nprint(imp[:10].Features);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 18. Summarize the learnings of ED\n\n1. Data is higly imblaced, target distribtion is:\n    >0 = 96.36 %\n    \n    >1 = 3.64 %\n    \n2 Most of the features are uncorrelated\n\n3. Top 10 ordered important features\n\n> 1.    ps_car_13    \n\n> 2.    ps_reg_03    \n\n> 3.    ps_car_14    \n\n> 4.    ps_calc_10   \n\n> 5.    ps_calc_14   \n\n> 6.    ps_calc_11   \n\n> 7.    ps_car_11_cat\n\n> 8.    ps_ind_15    \n\n> 9.    ps_ind_03    \n\n> 10.    ps_calc_01\n"},{"metadata":{},"cell_type":"markdown","source":"### Spliting data in feature & target"},{"metadata":{"trusted":true},"cell_type":"code","source":"x= df.drop(['target','id'], axis=1)\ny= df['target']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  Spliting data in train test\n> using 70 percentage for training and 30 percentage for testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split as tts\nX_train,X_test,y_train,y_test = tts(x, y, test_size = 0.3,random_state = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n# Fit only to the training data\nscaler.fit(X_train)\n# Now apply the transformations to the data:\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression (Before Resampling)"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_= df1.drop(['target','id'], axis=1)\ny_= df1['target']\n\nfrom sklearn.model_selection import train_test_split as tts\nX_Train,X_Test,y_Train,y_Test = tts(x_, y_, test_size = 0.3,random_state = 1)\n\nlog_reg = LogisticRegression()\nlog_reg.fit(X_Train, y_Train)\n\n# y_pred_train = log_reg.predict(X_Train)\ny_pred_logreg1 = log_reg.predict(X_Test)\n\naccuracy_result(y_Test, y_pred_logreg1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modeling Questions and their Answers \n#### Q. The Simple Logistic Regression Model seems to have high accuracy. Is that what we need at all? What is the problem with this model?\nAns.: Simple Logistic Regression Model seems to have high accuracy because of highly imbalanced data. When we use accuracy, we assign equal cost to false positives and false negatives. When that data set is imbalanced - say it has 96% of instances in one class and only 4 % in the other - there is a great way to lower the cost. Predict that every instance belongs to the majority class, get accuracy of 96% which is very high accuracy.\n\n> Accuracy = (correct classifications / number of classifications)\n\n#### Q. Why do you think f1-score is 0.0?\n**Ans.:** In this model, the Precision and Recall both are Zero due to which F1 score also become zero.\n\n#### Q. What is the precision and recall score for the model?\n**Ans.:** In this model, the Precision and Recall both are Zero"},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression (After Resampling)\n\n#### 1. Fitting a Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg = LogisticRegression()\nlog_reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression (After Resampling)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"## 1. Fitting a Logistic Regression\nlog_reg = LogisticRegression()\nlog_reg.fit(X_train, y_train)\n\n## 2. Predicting on Train and test data\n\ny_pred_train = log_reg.predict(X_train)\ny_pred_logreg2 = log_reg.predict(X_test)\n\n## 3. Using function for evaluating the model output\n\naccuracy_result(y_test, y_pred_logreg2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Q. What is the accuracy score and f1-score for the improved Logistic Regression model?**\n\n**Q. Why do you think f1-score has improved?**\n\n**Ans.:**\n\n**Logistic regression model (Before Resampling)**\n* Accurecy = 0.964\n* F1 score = 0.0  \n\n**Logistic regression model (After Resampling)**\n* Accurecy = 0.589\n* F1 score = 0.573\n\nIn above given data after resampling the F1 score is 0.573 which is improved F1 score in compare to previous score and it shows improved logistic regression model."},{"metadata":{},"cell_type":"markdown","source":"### Support Vector Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_tr=X_train[:10000,:]\ny_tr=y_train[:10000]\n\n## 1. svm Classifier with linear kernel\n\n#Create a svm Classifier\nclf = svm.SVC(kernel='linear')\n# FIT SVC ON TRAINING DATA\nclf.fit(x_tr, y_tr)\n\n## 2. Predicting on Train and test data\n\n# y_pred_train = clf.predict(X_train)\ny_pred_svc = clf.predict(X_test)\n\n#  model output\naccuracy_result(y_test, y_pred_svc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Q.: For model LinearSVC play with parameters – dual, max_iter and see if there is any improvement.**\n\nAns.: Not any Significance Improvement\n    \n**Q.: SVC with Imbalance Check & Feature Optimization & only 100K Records → is there improvement in scores?**\n\nAns.: I fitted the SVC model on 10K dataset because on 100K dataset not able to run the model."},{"metadata":{},"cell_type":"markdown","source":"### XGBoost Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"## 1. Initializing XGboost Classifier\n\nxg_cls = XGBClassifier(objective='binary:logistic', colsample_bytree = 0.3, learning_rate = 0.1,\n                max_depth = 50, alpha = 10, n_estimators = 100)\nxg_cls.fit(X_train, y_train)\n\n## 2. Predicting on Train and test data\n\n# y_pred_train = xg_cls.predict(X_train)\ny_pred_xgb = xg_cls.predict(X_test)\n\n# function for evaluating the model output\naccuracy_result(y_test, y_pred_xgb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Q. XGBoost is one the better classifiers -- but still f1-score is very low. What could be the reason?**\n\nIn my model ,I'm getting f1 score near to 1, that indicate a best fitted model.\n\n**Q. What is the increase in number of features after one-hot encoding of the data?**\n\nAns.: There is no need of One-hot encoding because it has been previously done.\n\n**Q. Is there any improvement in scores after encoding?**\n\nAns.: Not happened (because There is no need of One-hot encoding so I have not done it)\n\n**Q. If not missing a positive sample is the priority which model is best so far?**\n\nAns.:  XGBoost model is performing best.Count of missing positive sample is 6 only.\n     \n     **XGBoost CONFUSION MATRIX:\n     \n     [[172287      6]\n      \n     [     0 171818]]\n\n\n**Q. If not marking negative sample as positive is top priority, which model is best so far?**\n\nAns.:  XGBoost model is performing best. No misclassification for negative sample as positive.\n     \n     **XGBoost CONFUSION MATRIX:\n     \n     [[172287      6]\n      \n     [     0 171818]]\n\n"},{"metadata":{},"cell_type":"markdown","source":"### Adaboost classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create adaboost classifer object\nadaBoost = AdaBoostClassifier(n_estimators=50, learning_rate=1, random_state=0)\n\n# Train Adaboost Classifer\nmodel1 = adaBoost.fit(X_train, y_train)\n\n\n#Predict the response for test dataset\ny_pred_ada = model1.predict(X_test)\n\naccuracy_result(y_test, y_pred_ada)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Q.: Do you think using AdaBoost can give any significant improvement over XGBoost?**\n\n**Ans.:** No improvement in AdaBoost model result because In my case XGBoost model giving much more better result (Accuracy and F1 score) in compare to AdaBoost model."},{"metadata":{},"cell_type":"markdown","source":"### MLP Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the model\nmlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10),activation='logistic', max_iter=200)\nmlp.fit(X_train, y_train.values.ravel())\n\n# Prediction on x_test\ny_predic = mlp.predict(X_test)\naccuracy_result(y_test,y_predic)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Q.: MLPClassifier is the neural network we are trying. But how to choose the right no. of layers and size?**\n\n**Q.: At what layer size we get the best f1-score?**\n\n**Ans.:**\n\nIn Generally, you can't analytically calculate the number of layers or the number of nodes to use per layer in an ANN to address a specific real-world predictive modeling problem, But there are many methods for determining the correct number of neurons to use in the hidden layers, such as the following:\n\n * The no. of hidden neurons should be between the size of the input layer and the size of the output layer.\n * The no. of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer.\n * The no. of hidden neurons should be less than twice the size of the input layer."},{"metadata":{},"cell_type":"markdown","source":"## Final Result Comperison"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = {'Log_Reg(Before Resamp)':[np.round(f1_score(y_Test, y_pred_logreg1),3), np.round(metrics.accuracy_score(y_Test, y_pred_logreg1),3)],\n        'Log_Reg(After Resamp)':[np.round(f1_score(y_test, y_pred_logreg2),3), np.round(metrics.accuracy_score(y_test, y_pred_logreg2),3)],\n        'SVC':[np.round(f1_score(y_test, y_pred_svc),3), np.round(metrics.accuracy_score(y_test, y_pred_svc),3)],\n        'XGBoost':[np.round(f1_score(y_test, y_pred_xgb),3), np.round(metrics.accuracy_score(y_test, y_pred_xgb),3)],\n        'AdaBoost':[np.round(f1_score(y_test, y_pred_ada),3), np.round(metrics.accuracy_score(y_test, y_pred_ada),3)],\n        'MLP Classifier':[np.round(f1_score(y_test, y_predic),3), np.round(metrics.accuracy_score(y_test, y_predic),3)]}\n\ndf_result=pd.DataFrame(data, index = ['F1_score', 'Accuracy']).T\ndf_result","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**After comparing the F1- score and Accuracy of all used Machine Learning models, we found that XGBoost model is best performing and giving best result with respect to all other model.**"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}